---
title: "retningsafledede"
---

[Introduktion]{.underline}

I det almindelige gymnasiepensum indgår nogle vigtige begreber indenfor
infinitesimalregningen for funktioner af en og to variable. For
funktioner af en variabel siges en funktion $f$ at være kontinuert i et
punkt $x_{0}$, hvis funktionsværdien $f(x)$ nærmer sig funktionsværdien
$f(x_{0})$ når x nærmer sig $x_{0}$.

$\lim_{x \rightarrow x_{0}}{f\left( x \right) = f(x_{0})}$.

Funktionen $f$ siges at være differentiabel i $x_{0}$, hvis hældningen
af sekanterne gennem de to punkter $(x_{0},f\left( x_{0} \right))$ og
$(x,f\left( x \right))$ på grafen for $f$ nærmer sig et fast tal
$f'(x_{0})$, når x nærmer sig $x_{0}$.

$\lim_{x \rightarrow x_{0}}{\frac{f\left( x \right) - f(x_{0})}{x - x_{0}} = f'(x_{0})}$.

Intuitivt kan man tænke på egenskaben kontinuitet i et punkt, som at
grafen for funktionen ikke har et spring i punktet, og på egenskaben
differentiabilitet i et punkt, som at grafen for funktionen hverken har
spring eller knæk i punktet. Hældningen $f'(x_{0})$ i punktet
$(x_{0},f\left( x_{0} \right))$ på grafen er så en grænseværdi af nogle
sekanthældninger, som hver for sig er gennemsnitshældninger for et
mindre og mindre stykke af grafen. Har man studeret grænseværdibegrebet
lidt nærmere, ved man, at den intuitive fortolkning ikke er særligt
præcis og heller ikke helt rigtig men alligevel er god til at give en
forståelse af gymnasiematematikken.

For funktioner af to variable siges en funktion $f$ at være kontinuert i
et punkt ${(x}_{0},y_{0})$, hvis funktionsværdien $f(x,y)$ nærmer sig
funktionsværdien $f(x_{0},y_{0})$ når $(x,y)$ nærmer sig
${(x}_{0},y_{0})$.

$\lim_{(x,y) \rightarrow (x_{0},y_{0})}{f\left( x,y \right) = f(x_{0},y_{0})}$.

Definitionen er direkte overført fra den tilsvarende definition for
funktioner af en variabel. Man kan desværre ikke tilsvarende genbruge
differentiabilitetsbegrebet fra funktioner af en variabel

$\lim_{(x,y) \rightarrow (x_{0},y_{0})}{\frac{f\left( x,y \right) - f\left( x_{0},y_{0} \right)}{\left( x,y \right) - {(x}_{0},y_{0})} = f'(x_{0},y_{0})}$,

Her giver brøken på venstre side repræsenterende sekanthældningen ikke
mening, da man ikke kan dividere med et punkt eller en vektor. I stedet
tager man udgangspunkt i en alternativ definition af differentiabilitet
for funktioner af en variabel, hvor man har kaldt skridtet fra $x_{0}$
til $x$ for $h$:

$\lim_{h \rightarrow 0}{\frac{f\left( x_{0} + h \right) - f(x_{0})}{h} = f'(x_{0})}$.

Man bruger det til at definere de to første ordens partielle afledede
for en funktion $f$ af to variable

$\lim_{h \rightarrow 0}{\frac{f\left( x_{0} + h,y_{0} \right) - f(x_{0},y_{0})}{h} = f_{x}^{'}(x_{0},y_{0})}$

$\lim_{h \rightarrow 0}{\frac{f\left( x_{0},y_{0} + h \right) - f(x_{0},y_{0})}{h} = f_{y}^{'}(x_{0},y_{0})}$

hvis grænserne eksisterer. Her tager man et skridt $h$ i enten x-aksens
retning eller y-aksens retning ud fra punktet $(x_{0},y_{0})$ og
beregner en hældning af grafen i den retning ved hjælp af en grænseværdi
af sekanthældninger for snitfunktionerne $f(x,y_{0})$ og $f(x_{0},y)$,
som hver for sig er almindelige funktioner af en variabel, da man kun
ændrer enten x-koordinaten eller y-koordinaten.

Gradientvektoren defineres som vektoren med de partielle afledede som
koordinater

$\nabla f\left( x_{0},y_{0} \right) = \begin{pmatrix}
f_{x}^{'}\left( x_{0},y_{0} \right) \\
f_{y}^{'}\left( x_{0},y_{0} \right) \\
\end{pmatrix}$.

Det oplyses i gymnasiepensum, at denne vektor angiver den retning, man
skal bevæge sig væk fra punktet $(x_{0},y_{0})$, for at
funktionsværdierne $f(x,y)$ vokser mest muligt. Vi vil i det følgende se
nærmere på denne egenskab og bruge den til at løse optimeringsproblemer
numerisk.

[Retningsafledede]{.underline}

Vi vil nu se på væksten i andre retninger end blot i aksernes retning.
Vi angiver retningen med en enhedsvektor, dvs en vektor med længde 1.

$\overrightarrow{u} = \begin{pmatrix}
u_{1} \\
u_{2} \\
\end{pmatrix}$

Vi definerer nu den retningsafledede af $f$ i punktet $(x_{0},y_{0})$ i
retningen $\overrightarrow{u}$ ved

$D_{\overrightarrow{u}}f\left( x_{0},y_{0} \right) = \lim_{h \rightarrow 0}\frac{f\left( x_{0} + hu_{1},y_{0} + hu_{2} \right) - f(x_{0},y_{0})}{h}$

hvis grænsen eksisterer.

Bemærk, at hvis $\overrightarrow{u}$ peger i x-aksens retning, så bliver
den retningsafledede til $f_{x}^{'}(x_{0},y_{0})$, og hvis den peger i
y-aksens retning, bliver den til $f_{y}^{'}(x_{0},y_{0})$. Man udregner
en sekanthældning ved at tage et skridt $h$ i $\overrightarrow{u}$'s
retning og dividere den fundne funktionstilvækst med h. Derefter lader
man $h$ gå mod 0. Det giver hældningen af grafen for $f$ i punktet
$(x_{0},y_{0})$ i retningen $\overrightarrow{u}$.

Det viser sig, at man kan udregne de retningsafledede med et
prikprodukt:

$D_{\overrightarrow{u}}f\left( x_{0},y_{0} \right) = \nabla f(x_{0},y_{0}) \bullet \overrightarrow{u}$

Vi vil argumentere for formlen, men lad os først se på konsekvenserne af
den. Vi ved fra almindelig vektorregning, at

$\overrightarrow{a} \bullet \overrightarrow{b} = \left| \overrightarrow{a} \right| \bullet \left| \overrightarrow{b} \right| \bullet cos(v)$

hvor $v$ er vinklen mellem de to vektorer. Da
$\left| \overrightarrow{u} \right| = 1$ betyder det, at

$D_{\overrightarrow{u}}f\left( x_{0},y_{0} \right) = \left| \nabla f(x_{0},y_{0}) \right| \bullet cos(v)$

hvor $v$ er vinklen mellem gradientvektoren
$\nabla f\left( x_{0},y_{0} \right)\ $og den valgte retning
$\overrightarrow{u}$. Det følger, at $f$ vokser mest når
$\overrightarrow{u}\ $peger i $\nabla f(x_{0},y_{0})$'s retning og
aftager mest i den modsatte retning

$D_{\overrightarrow{u}}f\left( x_{0},y_{0} \right) = \ \ \ \left| \nabla f(x_{0},y_{0}) \right|$
når $v = 0^{{^\circ}}$

$D_{\overrightarrow{u}}f\left( x_{0},y_{0} \right) = - \left| \nabla f(x_{0},y_{0}) \right|$
når $v = 180^{{^\circ}}$

[Middelværdisætningen]{.underline}

For at argumentere for formlen for de retningsafledede udregnet som et
prikprodukt skal vi bruge middelværdisætningen for funktioner af en
variabel:

[Sætning]{.underline}

Hvis $f$ er kontinuert på $\left\lbrack a;b \right\rbrack$ og
differentiabel i $\left\rbrack a;b \right\lbrack$ så findes der et punkt
$c$ mellem $a$ og $b$, så hældningen i punktet $c$ er lig med
middelværdien af hældningen på hele intervallet
$\left\lbrack a;b \right\rbrack$

$f^{'}\left( c \right) = \frac{f\left( b \right) - f(a)}{b - a}$

Resultatet i middelværdisætningen kan omskrives til

$f\left( b \right) - f\left( a \right) = f^{'}\left( c \right) \bullet (b - a)$

Som er det, vi får brug for. Resultatet i middelværdisætningen virker
indlysende korrekt, hvis man prøver at tegne situationen, og beviset for
middelværdisætningen kan findes i flere gymnasiebøger.

Inden vi går til argumentet for formlen for de retningsafledede, vil vi
se på et enkelt eksempel med middelværdisætningen:

[Eksempel]{.underline}

Funktionen $f\left( x \right) = \sqrt{x}$ er kontinuert på
$\left\lbrack 0;4 \right\rbrack$ og differentiabel i
$\left\rbrack 0;4 \right\lbrack$, så betingelserne for at bruge
middelværdisætningen er opfyldt.

Der findes så et tal $c$ mellem 0 og 4, så
$f^{'}\left( c \right) = \frac{f\left( 4 \right) - f(0)}{4 - 0}$.

Vi ved, at $f^{'}\left( x \right) = \frac{1}{2\sqrt{x}}$ så ligningen
ovenfor bliver
$\frac{1}{2\sqrt{c}} = \frac{\sqrt{4} - \sqrt{0}}{4 - 0}$, hvilket giver
$c = 1$.

Hældningen af grafen for $f\left( x \right) = \sqrt{x}$ i punktet
$c = 1$ er altså det samme som middelværdien af hældningen af grafen på
hele intervallet
$\left\lbrack a;b \right\rbrack = \left\lbrack 0;4 \right\rbrack$, dvs
hældningen af den sekant, der forbinder startpunktet
$(0,f\left( 0 \right))$ og slutpunktet $(4,f\left( 4 \right))$.

Illustration:

![](media/image1.png){width="6.6930555555555555in"
height="3.8229166666666665in"}

Middelværdisætningen siger altså bare, at hvis man forbinder start og
slutpunktet -- den blå linje -- og udregner dens hældning, så kan man
altid finde et punkt i det indre af intervallet, hvor tangenten i
punktet -- den grønne linje -- har samme hældning.

Vi vender nu tilbage til definitionen af de retningsafledede og
omskriver funktionstilvæksten for at kunne bringe middelværdisætningen i
spil

$f\left( x_{0} + h \bullet u_{1},y_{0} + h \bullet u_{2} \right) - f(x_{0},y_{0})$

=
$f\left( x_{0} + h \bullet u_{1},y_{0} + h \bullet u_{2} \right) - f\left( x_{0},y_{0} + h \bullet u_{2} \right) + f\left( x_{0},y_{0} + h \bullet u_{2} \right) - f(x_{0},y_{0})$

Bemærk, at vi har lagt et led til og trukket det samme led fra. De to
første led afviger nu kun på x-koordinaten, og de to sidste led afviger
kun på y-koordinaten. Ved at bruge middelværdisætningen på de to
snitfunktioner $f\left( x,y_{0} + h \bullet u_{2} \right)$ som en
funktion af x og $f(x_{0},y)$ som en funktion af y, får vi nu følgende:

$f\left( x_{0} + h \bullet u_{1},y_{0} + h \bullet u_{2} \right) - f\left( x_{0},y_{0} + h \bullet u_{2} \right) = f_{x}^{'}(c_{1},y_{0} + h \bullet u_{2}) \bullet h \bullet u_{1}$

$f\left( x_{0},y_{0} + h \bullet u_{2} \right) - f\left( x_{0},y_{0} \right) = f_{y}^{'}(x_{0},c_{2}) \bullet h \bullet u_{2}$

Her har vi brugt, at den afledede af en snitfunktion, hvor vi kun
varierer x er $f_{x}^{'}$, og den afledede af en snitfunktion, hvor vi
kun varierer y er $f_{y}^{'}$. Tallet $c_{1}$ ligger mellem $x_{0}$ og
$x_{0} + h \bullet u_{1}$, og tallet $c_{2}$ ligger mellem $y_{0}$ og
$y_{0} + h \bullet u_{2}$.

Vi har nu ved at indsætte omskrivningen i definitionen for den
retningsafledede:

$D_{\overrightarrow{u}}f\left( x_{0},y_{0} \right) = \lim_{h \rightarrow 0}\frac{f\left( x_{0} + hu_{1},y_{0} + hu_{2} \right) - f(x_{0},y_{0})}{h}$

=
$\lim_{h \rightarrow 0}\frac{f_{x}^{'}\left( c_{1},y_{0} + h \bullet u_{2} \right) \bullet h \bullet u_{1} + f_{y}^{'}(x_{0},c_{2}) \bullet h \bullet u_{2}\ }{h}$

=$\underset{h \rightarrow 0}{\text{\ lim}}f_{x}^{'}\left( c_{1},y_{0} + h \bullet u_{2} \right) \bullet u_{1} + f_{y}^{'}(x_{0},c_{2}) \bullet u_{2}\ $

= $\lim_{h \rightarrow 0}\begin{pmatrix}
f_{x}^{'}\left( c_{1},y_{0} + h \bullet u_{2} \right) \\
f_{y}^{'}(x_{0},c_{2}) \\
\end{pmatrix} \bullet \begin{pmatrix}
u_{1} \\
u_{2} \\
\end{pmatrix}$

hvis grænsen eksisterer.

Bemærk nu, at hvis både $f_{x}^{'}(x,y)$ og
$f_{y}^{'}\left( x,y \right)$ eksisterer og er kontinuerte på en omegn
af $(x_{0},y_{0})$, så er betingelserne for vores brug af
middelværdisætningen opfyldt for små værdier af $h$, og da

$\lim_{h \rightarrow 0}\left( c_{1},y_{0} + h \bullet u_{2} \right)$ =
$(x_{0},y_{0})$

$\lim_{h \rightarrow 0}\left( x_{0},c_{2} \right) = \ (x_{0},y_{0})$

vil ovenstående grænseværdi på grund af kontinuiteten af de partielle
afledede eksistere og give

det ønskede resultat

$D_{\overrightarrow{u}}f\left( x_{0},y_{0} \right) = \begin{pmatrix}
f_{x}^{'}\left( x_{0},y_{0} \right) \\
f_{y}^{'}(x_{0},y_{0}) \\
\end{pmatrix} \bullet \begin{pmatrix}
u_{1} \\
u_{2} \\
\end{pmatrix} = \nabla f(x_{0},y_{0}) \bullet \overrightarrow{u}$

[Optimering]{.underline}

Betragt en funktion $\text{f\ }$givet ved forskriften
$f\left( x,y \right) = \left( \left( x - 5 \right)^{2} + 3 \right) \bullet \left( 5 + \left( y - 10 \right)^{2} \right) + 30$.

Det ses let fra forskriften, at funktionen har et minimum på 45 som fås
når $\left( x,y \right) = (5,10)$.

Grafen ser således ud:

![](media/image2.png){width="1.5207720909886264in"
height="1.3839293525809273in"}

Man kan lave en iterativ metode til at finde minimumspunktet ved at
udnytte egenskaben ved gradientvektoren:

-   Vælg et startpunkt
    $\left( x\left( 0 \right),y\left( 0 \right) \right)\ $som et første
    gæt på et minimumspunkt.

-   Gå så et lille skridt i retningen
    $- \nabla f(x\left( 0 \right),y\left( 0 \right))$. Det giver så det
    næste punkt $(x\left( 1 \right),y\left( 1 \right))$, som
    forhåbentlig er et bedre bud på et minimumspunkt.

-   Processen foregår i definitionsmængden, men på grafen svarer det til
    at gå et lille stykke den stejleste vej ned ad bakken.

-   Processen itereres så gentagne gange indtil man forhåbentlig når
    minimumspunktet.

Vælger vi med den konkrete funktion et startpunkt på

$\left( x\left( 0 \right),y\left( 0 \right) \right) = ( - 3,4)$

og vælger vi i hvert skridt at lægge -0,001 gange gradientvektoren i
punktet til, så

bliver nogle af de følgende punkter og en illustration af udviklingen:

![Et billede, der indeholder tekst Automatisk genereret
beskrivelse](media/image3.png){width="1.9166666666666667in"
height="2.75in"}![](media/image4.png){width="2.6503772965879264in"
height="2.7400306211723535in"}

Vi ser at den iterative gradientnedstigning faktisk nærmer sig det
globale minimumspunkt, så i hvert fald i dette konkrete tilfælde virker
metoden.

[Træning af neurale netværk]{.underline}

At lede efter et globalt minimumspunkt eller i det mindste et brugbart
lokalt minimumspunkt for en funktion af rigtig mange variable er et
problem, man står overfor, når man skal have trænet et neuralt netværk
og have fastlagt en masse vægte i netværket.

Det kan ikke gøres analytisk, så derfor bruger man netop en iterativ
proces baseret på gradientnedstigning som metoden til at finde frem til
minimumspunktet. Eksemplet ovenfor illustrerer derfor ideen bag en
central del af træningen af et neuralt netværk.

En gennemgang af ideerne bag denne træning af et neuralt netværk med
flotte illustrationer kan f.eks. ses i en youtube-video fra 3Blue1Brown
"Gradient descent, how neural networks learn":

<https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi>

Bemærk, at der mod slutningen af videoen også er en henvisning til og
anbefaling af en gratis bog om kunstig intelligens af Michael Nielsen:

<https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbUlOUVN3VnhEREF0TTVRaVplZGZTUnFiVG1Td3xBQ3Jtc0tsdW9JVlRYSjQtdVUxMEFWei1GeS1WeDdfc0FqcklQdVlPV0JUeTBfVjlfWlRDNTR0T0plb21oMmZDM3o1OE9FODNzejRaeXZxNzdOMXVCODdwM09LcElvY0F2VUhUa0xNME1PSWlsREJ3dy1nTl9wbw&q=http%3A%2F%2Fneuralnetworksanddeeplearning.com%2F&v=IHZwWFHWa-w>
